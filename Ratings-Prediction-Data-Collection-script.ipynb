{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa895ab9",
   "metadata": {},
   "source": [
    "# Ratings Prediction: Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0b3f19",
   "metadata": {},
   "source": [
    "### Objective:\n",
    "To scrape the reviews of different laptops, Phones, Headphones, smart watches, Professional Cameras, Printers, monitors, Home theater, router from different e-commerce websites.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1585d8",
   "metadata": {},
   "source": [
    "### Columns required:\n",
    "\n",
    "* reviews of the product.\n",
    "\n",
    "* rating of the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7cc677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the neccessary libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from  bs4 import BeautifulSoup\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27c2ea1",
   "metadata": {},
   "source": [
    "# Scraping for ratings & reviews from Flipkart.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c768829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path for chromedriver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "# to open the homepage of flipkart.com\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#clicking on cancel buttopn \n",
    "driver.find_element_by_xpath(\"//div[@class='_2QfC02']/button\").click()\n",
    "search_items = ['Laptops','Monitors','Phones','Smart watches']\n",
    "\n",
    "#empty lists\n",
    "review_title = []\n",
    "review_text = []\n",
    "ratings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae6ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function to scrape the data\n",
    "def scrape():    \n",
    "        for i in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\"):\n",
    "            review_text.append(i.text)\n",
    "        for i in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "            review_title.append(i.text)\n",
    "        for i in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']/../div\"):\n",
    "            ratings.append(i.text)\n",
    "        return\n",
    "urls=[]\n",
    "for i in search_items:\n",
    "    # Find the search bar\n",
    "    srcbar = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input\")\n",
    "    srcbar.clear()\n",
    "    srcbar.send_keys(i)\n",
    "    # Clicking on the search button\n",
    "    driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click()\n",
    "    time.sleep(2)\n",
    "    page = []\n",
    "    for i in driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/a\"):\n",
    "        page.append(i.get_attribute('href'))\n",
    "    for i in page[0:4]:\n",
    "        driver.get(i)\n",
    "        time.sleep(3)\n",
    "        items = driver.find_elements_by_xpath(\"//a[@class='_1fQZEK']\")\n",
    "        for i in items:\n",
    "            urls.append(i.get_attribute('href'))\n",
    "len(urls)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e782f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    for _ in range(2):\n",
    "        driver.execute_script(\"window.scrollBy(0,6000)\")\n",
    "        time.sleep(1)\n",
    "    # Clicking on all reviews\n",
    "    try:\n",
    "        btn=driver.find_element_by_xpath(\"//div[@class='_2c2kV-']/following::a\")\n",
    "        lnk = btn.get_attribute('href')\n",
    "        driver.get(lnk)\n",
    "        time.sleep(1)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    scrape()        \n",
    "    try:\n",
    "        n_page=driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/a\")\n",
    "        np=[]\n",
    "        for i in n_page:\n",
    "            np.append(i.get_attribute('href'))\n",
    "        for i in np[0:18]:\n",
    "            driver.get(i)\n",
    "            time.sleep(1)\n",
    "            scrape()\n",
    "    except: continue\n",
    "len(ratings), len(review_text), len(review_title)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5632d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe\n",
    "df = pd.DataFrame({})\n",
    "df['Review_title'] = review_title\n",
    "df['Review_text'] = review_text\n",
    "df['Rating'] = ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9e1143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data into csv file\n",
    "df.to_csv(\"Flipkart_Reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49cb112",
   "metadata": {},
   "source": [
    "# Scraping for ratings & reviews from Amazon.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f079f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to open the homepage of amazon.com\n",
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "search_items = ['Laptops','Phones','Headphones','Smart watches']\n",
    "#empty lists\n",
    "review_title = []\n",
    "review_text = []\n",
    "ratings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in search_items:\n",
    "    srcbar = driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "    srcbar.send_keys(i)\n",
    "    driver.find_element_by_id(\"nav-search-submit-button\").click()  #clicking on search button\n",
    "    time.sleep(1)\n",
    "    item_url = []\n",
    "    for i in driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']/a\"):\n",
    "        item_url.append(i.get_attribute('href'))\n",
    "    for i in item_url:\n",
    "        driver.get(i)\n",
    "        time.sleep(1)\n",
    "        for _ in range(2):\n",
    "            driver.execute_script(\"window.scrollBy(0,6000)\")\n",
    "            time.sleep(1)\n",
    "        # Clicking on see all reviews\n",
    "        try:\n",
    "            driver.find_element_by_xpath(\"//a[@class='a-link-emphasis a-text-bold']\").click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        url_ = []\n",
    "         try:\n",
    "            two_str = driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[4]/td[2]/a\")\n",
    "            url_.append(two_str.get_attribute('href'))\n",
    "        except: pass\n",
    "        try:\n",
    "            three_str = driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[3]/td[2]/a\")\n",
    "            url_.append(three_str.get_attribute('href'))\n",
    "        except: pass\n",
    "        try:\n",
    "            one_str = driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[5]/td[2]/a\")\n",
    "            url_.append(one_str.get_attribute('href'))\n",
    "        except: pass\n",
    "        try:\n",
    "            five_str = driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[1]/td[2]/a\")\n",
    "            url_.append(five_str.get_attribute('href'))\n",
    "        except: pass\n",
    "        try:\n",
    "            four_str = driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[2]/td[2]/a\")\n",
    "            url_.append(four_str.get_attribute('href'))\n",
    "        except: pass\n",
    "        \n",
    "        for i in url_:\n",
    "            driver.get(i)\n",
    "            time.sleep(1)\n",
    "            for i in range(10):\n",
    "                ids = driver.find_elements_by_xpath(\"//div[@class='a-section a-spacing-none review-views celwidget']/div\")\n",
    "                comment_ids = []\n",
    "                for i in ids:\n",
    "                    comment_ids.append(i.get_attribute('id'))\n",
    "\n",
    "                for x in comment_ids:\n",
    "                    # Extract user ids from each user on a page\n",
    "                    try:\n",
    "                        review = driver.find_element_by_xpath('//*[@id=\"' + x +'\"]/div/div/div[2]/a[2]/span[1]')\n",
    "                        review_title.append(review.get_attribute(\"innerHTML\"))\n",
    "                    except NoSuchElementException:\n",
    "                        review_title.append('')\n",
    "\n",
    "                    try:\n",
    "                        rating = driver.find_element_by_xpath('//*[@id=\"' + x +'\"]/div/div/div[2]/a[1]/i/span[1]')\n",
    "                        ratings.append(rating.get_attribute(\"innerHTML\"))\n",
    "                    except NoSuchElementException:\n",
    "                        ratings.append('')\n",
    "\n",
    "                    try:\n",
    "                        text = driver.find_element_by_xpath('//*[@id=\"' + x +'\"]/div/div/div[4]/span/span')\n",
    "                        review_text.append(text.get_attribute(\"innerHTML\"))\n",
    "                    except NoSuchElementException:\n",
    "                        review_text.append('')\n",
    "                try:\n",
    "                    driver.find_element_by_xpath(\"//ul[@class='a-pagination']/li[2]/a\").click()\n",
    "                    time.sleep(3)\n",
    "                except : break \n",
    "len(ratings), len(review_title), len(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f27b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe\n",
    "df = pd.DataFrame({})\n",
    "df['Review_title'] = review_title\n",
    "df['Review_text'] = review_text\n",
    "df['Rating'] = ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450dc1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the scraped data into csv file\n",
    "df.to_csv(\"Amazon_Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e6688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the flipkart and amazon reviews files to combine them together into a single csv file\n",
    "Flipkart = pd.read_csv(\"Flipkart_Reviews.csv\")\n",
    "Amazon = pd.read_csv(\"Amazon_Reviews.csv\")\n",
    "Reviews = pd.concat([Amazon, Flipkart], ignore_index=True)\n",
    "Reviews.drop(columns = 'Unnamed: 0', inplace=True)\n",
    "Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc92b40f",
   "metadata": {},
   "source": [
    "# Saving the final collected data to a csv file for further processing & building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3292f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reviews.to_csv(\"Rating_Review_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d710d2d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
